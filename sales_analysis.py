# -*- coding: utf-8 -*-
"""Sales_Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EjMC9AOPOU-G5FvBdsQmJ0EX9RBPs3K8
"""

import pandas as pd
import re
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from scipy.stats import kurtosis, skew

df=pd.read_csv(r'/content/sales_data_sample.csv',encoding='latin-1')

df.head()

df.info()

"""Data Cleaning"""

# droping unnecessary columns
df.drop(columns=['CONTACTLASTNAME','CONTACTFIRSTNAME','PHONE','ADDRESSLINE2','POSTALCODE','STATE','TERRITORY'],axis = 1 , inplace = True)

# Fixing worng data type
df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'])
df.info()

"""**MONTHLY SALES**"""

#monthly sales of each financial year
monthly_sales = df.groupby(['YEAR_ID', 'MONTH_ID'])['SALES'].sum().unstack(level=0)

fig = go.Figure()

for year in monthly_sales.columns:
    fig.add_trace(go.Scatter(x=monthly_sales.index, y=monthly_sales[year],
                             mode='lines+markers',
                             name=str(year),
                             hovertemplate='Month: %{x}<br>Sales: %{y}<extra></extra>'))

fig.update_layout(title='MONTHLY SALES',
                  xaxis_title='MONTHS',
                  yaxis_title='SALES',
                  xaxis=dict(tickmode='linear', tick0=1, dtick=1),
                  hovermode='closest')

fig.show()

"""* In 2003, month of November had the best sales whereas month of January(1st) had the least amount of sales month.
* In 2004, least sales had in the month of Mar & April, whereas Dec had the best sale.
* In 2005, least sales had in April, best performance in May.

WEEKLY SALES
"""

# Extract day of the week from 'ORDERDATE' and create a new column 'weekday'
df['weekday'] = df['ORDERDATE'].dt.day_name()

# Map day names to abbreviations for plotting
day_mapping = {
    'Monday': 'Mon',
    'Tuesday': 'Tue',
    'Wednesday': 'Wed',
    'Thursday': 'Thu',
    'Friday': 'Fri',
    'Saturday': 'Sat',
    'Sunday': 'Sun'
}
df['weekday'] = df['weekday'].map(day_mapping)

#Revenue by week
order=['Mon','Tue','Wed', 'Thu','Fri','Sat', 'Sun']
weekly_revenue = df.groupby(['weekday', 'YEAR_ID'])[['SALES']].sum().reset_index()
ax=sns.barplot(data=weekly_revenue, x='weekday', y='SALES', hue='YEAR_ID', palette='viridis')
plt.title('weekly_revenue')
ax.set_xlabel('weekday')
ax.set_xticklabels(order)
weekly_revenue

"""**Observations:**  

- The data for 2005 includes only 5 months, which means it is incomplete and should be taken into account when analyzing yearly revenue.  
- From a monthly perspective, sales show a significant surge in the second half of the year (July to December), indicating that this might be a peak purchasing season for the industry.  
- From a weekly perspective, Thursday consistently has the lowest purchase rate, while purchasing activity strengthens as the weekend approaches, with weekends showing higher buying power compared to weekdays.

YEARLY SALES
"""

#Revenue by Year
yearly_sales=df.groupby(['YEAR_ID'])[['SALES']].sum(numeric_only=True).reset_index()
yearly_sales

#best year according to sales
# set the figure size
plt.figure(figsize=(7,5))

plt.title("YEARLY SALES")
plt.xlabel("YEARS")
plt.ylabel("SALES ( IN MILLIONS)")

# Calculate total sales for each year
yearly_sales = df.groupby('YEAR_ID')['SALES'].sum().reset_index()

# Create barplot without hue, using yearly_sales
z = sns.barplot(x="YEAR_ID", y="SALES", data=yearly_sales, palette="viridis", edgecolor="black", width=0.3)
sns.set_style("darkgrid")

# to add lables to each bar
tb = ["3.51M", "4.72M", '1.79M']
# adding to each container - iterate through containers and labels
for i, container in enumerate(z.containers):
    # Ensure we don't try to access labels beyond the length of tb
    if i < len(tb):
        z.bar_label(container, labels=[tb[i]], padding=3)

# adujust the legend size
# plt.legend(prop={"size":12})  # Remove legend since hue is not used
plt.plot()

"""Observations :

1) In 2003, Sales were around 3.5 Million 2) In 2004, Sales were around 4.7 Million,Highest sales in the 2004 Year. 3) In 2005, Sales were around 1.8 Million in just 5 Month, which was the very progressive year.
"""

#Make a plot function

def barplotter(data, colname1, colname2, title, **kwargs):
    plt.title(title)
    sns.barplot(data=data, x=data[colname1], y=data[colname2], palette='viridis', **kwargs)
    plt.xticks(rotation=60)

# Plot each productline sales
sales_by_productline=df.groupby(['PRODUCTLINE'])[['SALES']].sum().reset_index()
barplotter(data=sales_by_productline, colname1='PRODUCTLINE', colname2='SALES', title='2003-2005 Revenue by Productline',errorbar=None)

#  best quarter for each product line
quarterly_sales = df.groupby(['PRODUCTLINE', 'QTR_ID'])['SALES'].sum().reset_index()

fig = px.bar(quarterly_sales,
             x='PRODUCTLINE',
             y='SALES',
             color='QTR_ID',
             title='Sales FOR PRODUCTS SOLD ACCORDING TO QUARTER',
             labels={'SALES': 'Total Sales', 'QTR_ID': 'Quarter'},
             barmode='group')

fig.show()

"""Observation

* In 4th quarter of each products had maximum sales.
* In product categories, "Classic Cars" & "Vintage Cars" are the most demanded vehicles.
* The reason may be arrival of the Christmas Holidays.
"""

products = df.groupby(["PRODUCTLINE"])["SALES"].sum().reset_index()
products

fig = px.pie(products,
             names='PRODUCTLINE',
             values='SALES',
             title='Sales Distribution by Product Line')
fig.show()

products = df.groupby(["PRODUCTLINE"])['SALES'].sum().reset_index()
prices = df.groupby(["PRODUCTLINE"])["MSRP"].min().reset_index()  # MSRP - manufactured suggested retail price

result = pd.merge(products, prices)
result.SALES/100000

# set the width and height of the figure
plt.figure(figsize=(10,6))


ax= sns.barplot(data=result, x ="PRODUCTLINE", y = "SALES", hue="PRODUCTLINE", palette="viridis",
                             edgecolor="black", dodge=False, width=0.4)
ax2 = plt.twinx()
sns.lineplot(data=result, x="PRODUCTLINE", y='MSRP',ax=ax2, errorbar=None, color="b")

# adding labels
tb = ["3.91M", "1.16M", '976K', '714K', '226K', '1.12M', '1.90M' ]

# ADD TO THE CONTAINER
ax.bar_label(ax.containers[0], labels=tb, padding=3)
ax.bar_label(ax.containers[1], labels=tb, padding=3)
ax.bar_label(ax.containers[2], labels=tb, padding=3)
ax.bar_label(ax.containers[3], labels=tb, padding=3)
ax.bar_label(ax.containers[4], labels=tb, padding=3)
ax.bar_label(ax.containers[5], labels=tb, padding=3)
ax.bar_label(ax.containers[6], labels=tb, padding=3)

# adding title to the plot
plt.title("PRODUCTS SOLD vs SALES / MSRP")
ax.set(xlabel="PRODUCTS")
plt.show()

"""Observation

* The above graph shows that the products with the lowest price were sold the most, whereas the products with a high price were the least popular.

* From the plot, 'Classic Cars" & "Vintage Cars" are the most demanded products, 'Trains" was the least demanded product.


"""

# relationship between deal size and sales
fig = px.histogram(df, x='SALES', color='DEALSIZE',
                   labels={'SALES': 'Sales', 'DEALSIZE': 'Deal Size'},
                   title='Interactive Histogram of Sales by Deal Size')
fig.show()

#Top CUSTOERS
customer_sales = df.groupby('CUSTOMERNAME')['SALES'].sum().reset_index()

top_10_customers = customer_sales.nlargest(10, 'SALES')

top_customer_name = top_10_customers.loc[top_10_customers['SALES'].idxmax(), 'CUSTOMERNAME']
top_customer_sales = top_10_customers['SALES'].max()

fig = px.scatter(top_10_customers, x='CUSTOMERNAME', y='SALES',
                title='Top 10 Sales by Customer',
                labels={'CUSTOMERNAME': 'Customer Name', 'SALES': 'Sales'},
                color_continuous_scale=px.colors.sequential.Plasma)

fig.add_scatter(x=[top_customer_name], y=[top_customer_sales],
                mode='markers', marker=dict(color='red', size=12, symbol='star'),
                name='Top Customer')

fig.show()

"""Sales Distribution in  Country Segment"""

yearly_sales_by_country=df.groupby(['COUNTRY', 'YEAR_ID'])[['SALES']].sum().reset_index()

yearly_sales_by_country.head(20)

#Plot the revenue by year and country
plt.figure(figsize=(12,4))
plt.title('yearly_sales_by_country')
ax=sns.barplot(yearly_sales_by_country, x='COUNTRY', y='SALES',hue='YEAR_ID', palette='viridis')
xlabels=list(yearly_sales_by_country['COUNTRY'].unique())
ax.set_xticklabels(labels=xlabels, rotation=90)
plt.show()

"""Observations:
* Through the graph, 2004 has the highest revenue among 3 years ( however 2005 has only 5 months data, we will talk about it later)
* USA is the top contribution, France and Spain seems very close, they are  2nd and 3rd
"""

#Percentage of Each Country Revenue
df1=df.groupby(['COUNTRY'])[['SALES']].sum().reset_index()
total_sales=df1['SALES'].sum()

labels= []
for i in range(0,len(df1)):
    labels.append(df1['COUNTRY'][i])

colors = sns.color_palette('viridis')[0:len(df1)]
plt.pie(data=df1, x=df1['SALES'], autopct= '%1.2f%%', labels=labels, colors=colors)

plt.show()

#Product line by country
countrysales_by_productline=df.groupby(['COUNTRY', 'DEALSIZE'])[['SALES']].sum().reset_index()
countrysales_by_productline
#Plot Countrysales by productline
plt.figure(figsize=(20, 5))
barplotter(data=countrysales_by_productline, colname1='COUNTRY', colname2='SALES', title='Deal Size by Country', hue=countrysales_by_productline['DEALSIZE'])

# country with best sales
sales_by_country = df.groupby('COUNTRY')['SALES'].sum().reset_index()

top_10_countries = sales_by_country.nlargest(10, 'SALES')

fig = px.choropleth(top_10_countries,
                    locations='COUNTRY',
                    locationmode='country names',
                    color='SALES',
                    title='Top 10 Countries by Sales',
                    labels={'SALES': 'Sales'},
                    color_continuous_scale=px.colors.sequential.Plasma,
                    projection='natural earth')

fig.show()

#top 10 contribution to the total revenue

# First, create the DataFrames for each year's sales by country.
_2003sales_by_country_ds = df[df['YEAR_ID'] == 2003].groupby('COUNTRY')['SALES'].sum().reset_index()
_2004sales_by_country_ds = df[df['YEAR_ID'] == 2004].groupby('COUNTRY')['SALES'].sum().reset_index()
_2005sales_by_country_ds = df[df['YEAR_ID'] == 2005].groupby('COUNTRY')['SALES'].sum().reset_index()

# Now you can proceed with the calculations
_2003sales_by_country_ds['percent1']= round((_2003sales_by_country_ds['SALES']/ (yearly_sales['SALES'][0])*100), 2)
_2004sales_by_country_ds['percent2']= round((_2004sales_by_country_ds['SALES']/ (yearly_sales['SALES'][1])*100), 2)
_2005sales_by_country_ds['percent3']= round((_2005sales_by_country_ds['SALES']/ (yearly_sales['SALES'][2])*100), 2)

Top10_2003_2005=pd.concat([_2003sales_by_country_ds,_2004sales_by_country_ds,_2005sales_by_country_ds], axis=1)
Top10_2003_2005
print( '2003 top 10 countries takes up to', round(Top10_2003_2005['percent1'].sum(), 2), '% of the revenue')
print( '2004 top 10 countries takes up to', round(Top10_2003_2005['percent2'].sum(), 2), '% of the revenue')
print( '2005 top 10 countries takes up to', round(Top10_2003_2005['percent3'].sum(), 2), '% of the revenue')

# city with best sales
sales_by_city = df.groupby('CITY')['SALES'].sum().reset_index()
top_10_cities = sales_by_city.nlargest(10, 'SALES')

fig = px.bar(top_10_cities, x='CITY', y='SALES',
             title='Top 10 Cities by Sales',
             labels={'CITY': 'City', 'SALES': 'Sales'},
             color='SALES',
             color_continuous_scale=px.colors.sequential.Plasma)

fig.show()

"""Order Status Analysis"""

df['STATUS'].unique()

# Extract status that are not shipped
df_other_status= df[~(df['STATUS']=='Shipped')]

#Plot them in yearly manner
sns.histplot(data=df_other_status, x='STATUS', hue='YEAR_ID', multiple='stack')

"""Observations:

* Lastly I take a look at the order status, it can help to check if any orders are left behind
* Overall it looks good, mostly the orders that need to be handled (i.e In Proccess, Disputed) are in this year (assuming data collecting year is 2005)
* Only one order from 2004 is on hold, we can ask stakeholder to look after it


The plot shows that the large majority of the orders have been shipped. However, there is a minor (but non-negligible) fraction of the orders that was cancelled, it is on hold or disputed. It would be important to reduce the number of these unfavorable events in order to increase the profits.
"""

cancelled_count = (df.loc[df.STATUS == 'Cancelled']
    .groupby('COUNTRY')['ORDERNUMBER'].count()
    .reset_index(name='CANCELLED_COUNT')
    .sort_values('CANCELLED_COUNT', ascending=False))

cancelled_count

total_count = (df.loc[df.COUNTRY.isin(['Spain', 'Sweden', 'UK', 'USA'])]
        .groupby('COUNTRY')['ORDERNUMBER'].count()
        .reset_index(name='TOTAL_COUNT')
        .sort_values('TOTAL_COUNT', ascending=False))

cancelled_count = cancelled_count.merge(total_count)

cancelled_count['CANCELLED_FRACTION'] = (cancelled_count['CANCELLED_COUNT'] / cancelled_count['TOTAL_COUNT'] * 100).round(1)

cancelled_count = cancelled_count.sort_values('CANCELLED_FRACTION', ascending=False)

cancelled_count

fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(12,6))

ax1 = sns.barplot(data=cancelled_count, x='COUNTRY', y='TOTAL_COUNT',ax=ax1,palette='viridis')
ax1.set_title('Total Number of Orders', size=20)

ax2 = sns.barplot(data=cancelled_count, x='COUNTRY', y='CANCELLED_FRACTION',ax=ax2,palette='viridis')
ax2.set_title('Percentage of Cancelled Orders', size=20)

plt.tight_layout()

"""This plot highlights that the percentage of canceled orders is significantly high in certain countries, particularly Sweden and the UK. This is a concerning trend that requires immediate attention, and appropriate measures should be implemented to reduce these cancellation rates.

Unit Price Distribution
"""

# Unit Price Yearly
sns.scatterplot(data=df, x='PRICEEACH', y='QUANTITYORDERED', hue='YEAR_ID',palette='viridis')
plt.title("Unit Price x Q'ty Yearly Distribution")
plt.xlabel('UNIT PRICE')
plt.ylabel("QUANTITY ORDERED")
plt.show()

print('unit price min:' ,df['PRICEEACH'].min())
print('unit price max:' ,df['PRICEEACH'].max())
print('nin msrp :' ,df['MSRP'].min())
print('max msrp:' ,df['MSRP'].max())

#Plot the unitprice and productline

plt.title("Unit Price Among Different Products")
plt.xlabel('Unit price')
plt.ylabel("Quantity ")
sns.histplot(data=df, x='PRICEEACH', hue='PRODUCTLINE', multiple='fill', bins=range(26, 101, 5), palette='viridis')

sns.scatterplot(data=df, x='PRICEEACH', y='MSRP', hue='DEALSIZE')
sns.lineplot(x=(26, 26), y=(100, 100), linestyle='--', color='r')
plt.title("Unit Price x msrp Distribution")
plt.xlabel('Unit price')
plt.ylabel("MSRP ")

"""RFM Analysis

RFM (Recency, Frequency, Monetary) Analysis is a powerful customer segmentation technique used to evaluate and categorize customers based on their past purchasing behavior. It assesses:  

- **Recency**: How recently a customer made a purchase.  
- **Frequency**: How often a customer makes purchases within a specific time frame.  
- **Monetary**: The total spending of a customer during their purchasing history.  

By analyzing these factors, businesses can identify high-value customers, understand customer loyalty, and design targeted marketing strategies to enhance engagement and drive revenue.
"""

#Recency
df['LAST_PURCHASE_DATE'] = df.groupby('CUSTOMERNAME')['ORDERDATE'].transform(max)
df['LAST_PURCHASE_DATE'] = pd.to_datetime(df['LAST_PURCHASE_DATE'])

df["CUSTOMER_RECENCY_BEFORE_AVG"] = (df["ORDERDATE"] - df["LAST_PURCHASE_DATE"]).dt.days.abs()

df.drop('LAST_PURCHASE_DATE', axis=1, inplace=True)

recency_df = df.groupby('CUSTOMERNAME')['CUSTOMER_RECENCY_BEFORE_AVG'].mean().reset_index(name='RECENCY')

recency_df.head()

recency_df['RECENCY'].mean()

plt.figure(figsize=(12,6))

sns.histplot(data=recency_df, x='RECENCY',hue='RECENCY',palette='viridis')
plt.title('Customer Recency Distribution',size=30)

plt.tight_layout()

print(f"Skewness of the recency distribution: {skew(recency_df['RECENCY'])}")
print(f"Kurtosis of the recency distribution: {kurtosis(recency_df['RECENCY'])}")

"""**Frequency**"""

frequency_df = df.groupby('CUSTOMERNAME')['ORDERNUMBER'].nunique().reset_index(name='FREQUENCY')

plt.figure(figsize=(12,6))

sns.histplot(data=frequency_df, x='FREQUENCY')
plt.title('Customer Frequency Distribution',size=30)

plt.tight_layout()

print(f"Skewness of the frequency distribution: {skew(frequency_df['FREQUENCY'])}")
print(f"Kurtosis of the frequency distribution: {kurtosis(frequency_df['FREQUENCY'])}")

""" **Monetary**"""

monetary_value_df = df.groupby('CUSTOMERNAME')['SALES'].sum().reset_index(name='MONETARY_VALUE')

plt.figure(figsize=(12,6))

sns.histplot(data=monetary_value_df, x='MONETARY_VALUE')
plt.title('Customer Monetary Value Distribution',size=30)

plt.tight_layout()

print(f"Skewness of the monetary value distribution: {skew(monetary_value_df['MONETARY_VALUE'])}")
print(f"Kurtosis of the monetary value distribution: {kurtosis(monetary_value_df['MONETARY_VALUE'])}")

"""**The RFM dataframe is created by merging the previous dataframes (those of recency, frequency and monetary value)**"""

RFM_df = pd.merge(recency_df, frequency_df)

RFM_df = pd.merge(RFM_df, monetary_value_df)

num_features = ['RECENCY', 'FREQUENCY',	'MONETARY_VALUE']


fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(12,6))

ax1 = sns.boxplot(RFM_df[num_features[0]],ax=ax1)
ax1.set_title('Boxplot of '+str(num_features[0]),fontsize=20)

ax2 = sns.boxplot(RFM_df[num_features[1]],ax=ax2)
ax2.set_title('Boxplot of '+str(num_features[1]),fontsize=20)

ax3 = sns.boxplot(RFM_df[num_features[2]],ax=ax3)
ax3.set_title('Boxplot of '+str(num_features[2]),fontsize=20)

plt.suptitle('Boxplots of the Numerical Variables',size=30)

plt.tight_layout()

"""ConclusionsÂ¶

* 2005 Sales data only have 5 months, it need to be considered while checking yearly revenue
* Top 10 countries supply over 80-95% revenue
* The most popular product line is classic cars, and the biggest market is USA
* In 2003 & 2004 most order quantity are around 20-50pcs, in 2005 we can see some orders quantity are more than that section
* Deal size distribution : Medium > Small > Large
* Vintage car usually sells at lower price ($30-$50), Train ($45-70 )

* Plane and ships usually sells at higher price($60-$90); Motorcycle and classic cars have relative same proportion at each price range 7.
* Second-half year (Jul-Dec) has a speedy growth in sales then the first half, it might be a purchasing season for this industry
* From a weekly perspective, Thursday has the lowest buy rate thorughout a week, while closer to weekend stronger the purchasing power is than weekday
* There a few msrp(manufactured suggest resell price) lower than unit price, usually it stands for distrbutor is doing a money-losing business, it deserves further investigation
* Among orders that are not shipped, one 2004 order is on hold
"""